import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

import torch
import pandas as pd
import numpy as np
from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from igann import IGANN
from sklearn.metrics import mean_squared_error
from scipy.interpolate import CubicSpline

from Dashboard.data_preprocessing import load_and_preprocess_data
from Dashboard.model_adapter import ModelAdapter

import warnings



if __name__ == "__main__":
    print("Running main script")

# Load and split the data
X_train, X_test, y_train, y_test, task = load_and_preprocess_data("adult")

model = IGANN(task)
#model = IGANN(task='regression')
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
#mse = mean_squared_error(y_test, y_pred)
print(mse)
f1_test = f1_score(y_test, y_pred, average='weighted')
model.plot_single(show_n=8)
#model.plot_single(plot_by_list=['age', 'bmi', 'bp', 'sex', 's1', 's2'])

x = torch.tensor([-2.0177, -2.0005, -1.9949, -1.9894, -1.9832, -1.9777, -1.9086, -1.8396,
        -1.7705, -1.7015, -1.6324, -1.5634, -1.4943, -1.4253, -1.3562, -1.2872,
        -1.2181, -1.1491, -1.0800, -1.0455, -1.0110, -0.9420, -0.8729, -0.8039,
        -0.7348, -0.6658, -0.6312, -0.5967, -0.5277, -0.4586, -0.4241, -0.3896,
        -0.3205, -0.2515, -0.1824, -0.1134, -0.0789, -0.0443,  0.0247,  0.0592,
         0.0938,  0.1628,  0.1973,  0.2319,  0.3009,  0.3700,  0.4390,  0.5080,
         0.5771,  0.6461,  0.7152,  0.7497,  0.7842,  0.8533,  0.9223,  0.9914,
         1.0604,  1.0950,  1.1295,  1.1985,  1.2676,  1.3366,  1.4057,  1.4747,
         1.5438,  1.6819,  1.7509,  1.7854,  1.8200,  1.8890,  1.9580,  2.0271,
         2.0961,  2.1652,  2.2342,  2.3033,  2.3723,  2.4414,  2.5104,  2.7866,
         2.8557,  3.0628,  3.4771])

i = 0
y_hat_adapter = torch.tensor([3.54903812, 3.54095055, 3.53836257, 3.53577448, 3.53286297, 3.530275,3.4979247, 3.46557451, 3.43322421, 3.40087397, 3.36852373, 3.33617349, 3.30382319, 3.27147294, 3.2391227, 3.2067724, 3.17442222, 3.14207191, 3.10972167, 3.09354652, 3.0773714, 3.04502119, 3.01267092, 2.98032067,2.9479704, 2.91562016, 2.89944501, 2.88326992, 2.85091963, 2.81856939,2.80239427, 2.78621913, 2.75386887, 2.72151863, 2.68916837, 2.65681812,2.64064299, 2.62446786, 2.59211761, 2.57594248, 2.55976736, 2.52741711, 2.51124198, 2.49506685, 2.46271659, 2.43036633, 2.39801608, 2.36566584,2.33331556, 2.30096532, 2.26861508, 2.25243993, 2.23626481, 2.20391456,2.17156432, 2.13921405, 2.10686381, 2.09068866, 2.07451351, 2.04216332, 2.00981302, 1.97746278, 1.94511248, 1.9127623, 1.88041199, 1.81571151, 1.78336127, 1.76718612, 1.75101097, 1.71866078, 1.68631048, 1.65396024, 1.62160994, 1.58925964, 1.55690945, 1.52455927, 1.49220897, 1.45985867, 1.42750837, 1.2981074, 1.26575722, 1.16870631, 0.97460486])

#y_hat_new = model.init_classifier.coef_[0, i] * x.numpy() + model.init_classifier.intercept_

#print(y_hat_new)

# y_shape = torch.tensor([ 1.7561,  1.7388,  1.7332,  1.7276,  1.7214,  1.7158,  1.6465,  1.5773,
#          1.5083,  1.4396,  1.3711,  1.3030,  1.2351,  1.1676,  1.1005,  1.0339,
#          0.9678,  0.9023,  0.8373,  0.8051,  0.7731,  0.7097,  0.6472,  0.5857,
#          0.5253,  0.4661,  0.4370,  0.4083,  0.3521,  0.2977,  0.2712,  0.2453,
#          0.1950,  0.1473,  0.1024,  0.0606,  0.0410,  0.0224, -0.0118, -0.0278,
#         -0.0431, -0.0719, -0.0855, -0.0985, -0.1230, -0.1456, -0.1665, -0.1858,
#         -0.2036, -0.2201, -0.2353, -0.2424, -0.2493, -0.2623, -0.2743, -0.2854,
#         -0.2957, -0.3005, -0.3051, -0.3138, -0.3219, -0.3292, -0.3360, -0.3423,
#         -0.3480, -0.3580, -0.3623, -0.3643, -0.3662, -0.3698, -0.3730, -0.3759,
#         -0.3784, -0.3807, -0.3826, -0.3843, -0.3858, -0.3870, -0.3880, -0.3900,
#         -0.3900, -0.3892, -0.3840], dtype=torch.float64)

initial_feature_values = [
    0.231856, 0.853284, -0.320526, 0.715189, -0.734812, 0.853284, 0.024713, -0.320526,
    0.646142, -0.389573, -0.596716, -0.251478, -0.872907, -1.632431, 1.543761, -0.320526,
    -0.251478, 0.853284, 0.093760, 0.300903, 0.438999, -0.113383, -0.044335, 1.336618,
    -0.044335, -1.908622, -0.320526, -0.803859, 1.198523, -0.631240, -0.527669, -0.389573,
    0.646142, 0.715189, -0.734812, -0.320526, 1.198523, -0.389573, 0.162808, 0.646142,
    -0.941954, -1.080050, -0.251478, 0.922332, 1.474713, 0.162808, 0.162808, -0.527669,
    -0.320526, 0.162808, 0.438999, 0.369951, -0.872907, -0.527669, -0.044335, -0.803859,
    -2.017717, 0.059236, -1.287193, -0.665764, -0.389573, -0.182430, -0.596716, -0.320526,
    -0.596716, -0.355049, 0.922332, -0.527669, 0.438999, -0.803859, -0.596716, -1.701479,
    -0.078859, 2.855666, -0.389573, 0.162808, -0.044335, -0.458621, -0.665764, -0.803859,
    -0.320526, 1.474713, 0.024713, -1.356240, 0.024713, 0.646142, 0.093760, -0.182430,
    -0.596716, -0.803859, 0.577094, 0.784237, 2.165190, 0.577094, -0.458621, -0.527669,
    0.231856, -0.734812, -1.908622, 0.508046
]

# Sorting the list from low to high
sorted_numbers = pd.Series(sorted(initial_feature_values))
#initial_y_hat = pd.Series(model.init_classifier.coef_[0, i] * np.array(sorted(initial_feature_values))+ model.init_classifier.intercept_)




#model.plot_single(plot_by_list=['Age', 'Pclass', 'Sex', 'Embarked'])